{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing auxiliary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "\n",
    "# import pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# import tensorboard for logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# importing local code\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from datasets import SpectraDataset\n",
    "from models import FlexibleMLP, FlexibleBackwardMLP\n",
    "from loops import train_inverse,val_inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data into dataframe and clean them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename\n",
    "filename = '../DL-Assisted-NHA-Inverse-Design-/Dataset 6655.csv'\n",
    "\n",
    "# load in dataframe\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "# clean and rearrange data\n",
    "df['Spectra'] = df.values[:,5:][:,::-1].tolist()\n",
    "df['Spectra'] = df['Spectra'].apply(np.array)\n",
    "df.drop(df.columns[5:-1], axis=1, inplace=True)\n",
    "df.columns = ['Lattice','Material','Thickness','Radius','Pitch','Spectra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split dataframe in train/val and features/labels (X/y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select input features (y)\n",
    "X_df = df['Spectra']\n",
    "\n",
    "# select output labels (X)\n",
    "y_df = df[['Lattice','Material','Thickness','Radius','Pitch']]\n",
    "\n",
    "# split in training and validation set\n",
    "test_val_split = 0.1  # portion of data assigned to validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_df, y_df, test_size=test_val_split, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4851    [0.0177678, 0.0183766, 0.0188949, 0.0193357, 0...\n",
       "604     [0.0605793, 0.0606152, 0.05966, 0.0578818, 0.0...\n",
       "3891    [0.808406, 0.809849, 0.809093, 0.813381, 0.814...\n",
       "4817    [0.0190139, 0.0184199, 0.0178838, 0.0173684, 0...\n",
       "4047    [0.0225713, 0.0216366, 0.020792, 0.0200721, 0....\n",
       "                              ...                        \n",
       "3772    [0.859133, 0.864281, 0.86973, 0.871492, 0.8704...\n",
       "5191    [0.0287532, 0.0295561, 0.0304197, 0.0313051, 0...\n",
       "5226    [0.00877991, 0.00827171, 0.00775168, 0.0072616...\n",
       "5390    [0.0210184, 0.0225432, 0.0239345, 0.0252061, 0...\n",
       "860     [0.00322914, 0.003215, 0.00319104, 0.00315318,...\n",
       "Name: Spectra, Length: 5988, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5896    [0.0211472, 0.0229053, 0.0245804, 0.0261867, 0...\n",
       "217     [0.0477382, 0.0480398, 0.0481729, 0.0483546, 0...\n",
       "3214    [0.984692, 0.986608, 0.988734, 0.986776, 0.989...\n",
       "4516    [0.019098, 0.0185224, 0.0178235, 0.0170732, 0....\n",
       "1544    [0.0949851, 0.0943849, 0.0933566, 0.0924849, 0...\n",
       "                              ...                        \n",
       "425     [0.0150305, 0.0148046, 0.014522, 0.0143151, 0....\n",
       "4382    [0.0157072, 0.016587, 0.0175634, 0.0185691, 0....\n",
       "1002    [0.00339143, 0.00332585, 0.00328501, 0.0032520...\n",
       "681     [0.0225218, 0.022542, 0.0223468, 0.021951, 0.0...\n",
       "5719    [0.0261101, 0.0269595, 0.0279326, 0.0289608, 0...\n",
       "Name: Spectra, Length: 666, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lattice</th>\n",
       "      <th>Material</th>\n",
       "      <th>Thickness</th>\n",
       "      <th>Radius</th>\n",
       "      <th>Pitch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4851</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>105</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>100</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3891</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4817</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>145</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4047</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>125</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>145</td>\n",
       "      <td>55</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>150</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>110</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>130</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>50</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5988 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Lattice  Material  Thickness  Radius  Pitch\n",
       "4851        1         0        135     105    480\n",
       "604         0         0        125     100    475\n",
       "3891        0         2        150      50    520\n",
       "4817        1         0        130     145    475\n",
       "4047        1         0        100     125    475\n",
       "...       ...       ...        ...     ...    ...\n",
       "3772        0         2        145      55    475\n",
       "5191        1         0        145     150    475\n",
       "5226        1         0        150     110    485\n",
       "5390        1         1        100     130    480\n",
       "860         0         0        135      50    490\n",
       "\n",
       "[5988 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lattice</th>\n",
       "      <th>Material</th>\n",
       "      <th>Thickness</th>\n",
       "      <th>Radius</th>\n",
       "      <th>Pitch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5896</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>140</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>85</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>75</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4516</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>115</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>85</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>70</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4382</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>110</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>60</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>80</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5719</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>666 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Lattice  Material  Thickness  Radius  Pitch\n",
       "5896        1         1        120     140    480\n",
       "217         0         0        105      85    520\n",
       "3214        0         2        120      75    490\n",
       "4516        1         0        120     115    510\n",
       "1544        0         1        105      85    500\n",
       "...       ...       ...        ...     ...    ...\n",
       "425         0         0        115      70    515\n",
       "4382        1         0        115     110    500\n",
       "1002        0         0        140      60    485\n",
       "681         0         0        125      80    475\n",
       "5719        1         1        115     115    475\n",
       "\n",
       "[666 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate training and validation dataset\n",
    "training_dataset = SpectraDataset(X_train,y_train,direction='backward')\n",
    "val_dataset = SpectraDataset(X_val,y_val,direction='backward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C]: torch.Size([64, 200])\n",
      "Shape of y: torch.Size([64, 5]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "# batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders\n",
    "train_dataloader = DataLoader(training_dataset, batch_size=batch_size, shuffle= True, pin_memory=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, pin_memory=True)\n",
    "\n",
    "for X, y in val_dataloader:\n",
    "    print(f\"Shape of X [N, C]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing training device: cpu, gpu, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure of the neural network\n",
    "hidden_layers = [200, 500, 500, 500, 500, 500, 2, 3, 3]\n",
    "\n",
    "# instantiate model\n",
    "model = FlexibleBackwardMLP(hidden_layers=hidden_layers, activation=nn.GELU(), p=0.1).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base learning rate\n",
    "lr = 1.1e-4\n",
    "\n",
    "# defining loss and optimizer\n",
    "loss_reg = nn.MSELoss()\n",
    "loss_ce = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "tensor([[ 1.0743e-03, -1.7510e-03],\n",
      "        [ 5.4436e-04, -4.4834e-04],\n",
      "        [-4.1899e-07, -1.8757e-06],\n",
      "        [-1.2891e-05, -5.9752e-05],\n",
      "        [ 1.6954e-03, -9.3909e-04],\n",
      "        [-2.0303e-04,  7.7643e-05],\n",
      "        [-4.3899e-06, -1.0503e-05],\n",
      "        [-1.0106e-09,  4.0530e-07],\n",
      "        [ 5.0736e-05, -1.4764e-05],\n",
      "        [ 5.5014e-05, -2.9367e-05],\n",
      "        [ 2.6504e-05, -2.6217e-05],\n",
      "        [ 3.5299e-05, -1.6995e-05],\n",
      "        [ 3.3096e-06, -3.2115e-06],\n",
      "        [ 2.5623e-05, -4.0940e-05],\n",
      "        [-2.3711e-05, -2.6847e-05],\n",
      "        [ 4.1972e-05, -1.1248e-05],\n",
      "        [ 2.2882e-05,  1.2255e-06],\n",
      "        [ 1.4371e-05, -3.6050e-05],\n",
      "        [-7.0160e-06,  2.8960e-05],\n",
      "        [ 2.2769e-05,  3.3133e-05],\n",
      "        [ 3.9527e-05,  2.6858e-05],\n",
      "        [ 2.3989e-05, -2.5211e-06],\n",
      "        [ 5.7543e-06, -2.9620e-06],\n",
      "        [-2.0750e-05, -3.5393e-06],\n",
      "        [ 1.0889e-03, -8.1875e-04],\n",
      "        [ 1.6217e-05, -1.7386e-05],\n",
      "        [ 3.7058e-05, -6.8663e-08],\n",
      "        [ 1.4267e-03, -1.3930e-03],\n",
      "        [-4.2939e-05,  1.0980e-06],\n",
      "        [-1.5519e-04, -1.2182e-04],\n",
      "        [ 1.3245e-03, -5.7058e-04],\n",
      "        [ 3.9279e-04, -9.8731e-04],\n",
      "        [-5.2055e-06, -1.0430e-05],\n",
      "        [ 1.1768e-03, -3.4913e-05],\n",
      "        [ 2.2364e-05,  2.9858e-06],\n",
      "        [-6.6194e-06,  3.3266e-06],\n",
      "        [ 2.2748e-05, -1.7909e-05],\n",
      "        [-9.7807e-07,  1.7024e-05],\n",
      "        [ 2.8413e-05, -2.7883e-06],\n",
      "        [ 5.9046e-06, -4.5089e-05],\n",
      "        [ 1.3459e-06,  3.3442e-07],\n",
      "        [ 1.9299e-05, -2.0594e-05],\n",
      "        [ 2.7774e-03,  2.4377e-03],\n",
      "        [-3.6415e-05, -1.4327e-04],\n",
      "        [ 3.0064e-05, -6.7186e-05],\n",
      "        [ 1.5139e-03,  3.1173e-04],\n",
      "        [ 3.4204e-06,  1.9550e-06],\n",
      "        [-1.0757e-04,  4.1468e-06],\n",
      "        [ 3.9825e-04, -2.6800e-04],\n",
      "        [ 1.4856e-05, -5.6364e-06],\n",
      "        [ 1.6298e-06, -5.5271e-07],\n",
      "        [ 5.4046e-05, -3.6072e-05],\n",
      "        [ 9.4290e-04,  1.0230e-03],\n",
      "        [ 1.6187e-05,  1.1125e-05],\n",
      "        [ 4.3525e-06, -1.3550e-06],\n",
      "        [ 1.9942e-05, -3.3558e-05],\n",
      "        [ 3.9126e-05,  4.7026e-06],\n",
      "        [ 2.1039e-05, -1.9452e-04],\n",
      "        [ 6.9844e-06, -2.8334e-05],\n",
      "        [ 2.1352e-05, -3.7376e-05],\n",
      "        [ 2.3091e-05,  3.3642e-06],\n",
      "        [ 5.1659e-06,  1.0943e-05],\n",
      "        [ 1.8431e-03, -9.3773e-04],\n",
      "        [ 1.8964e-05,  1.2611e-05]], device='cuda:0', grad_fn=<MmBackward0>) tensor([[ 1.0743e-03, -1.7510e-03],\n",
      "        [ 5.4436e-04, -4.4834e-04],\n",
      "        [-4.1899e-07, -1.8757e-06],\n",
      "        [-1.2891e-05, -5.9752e-05],\n",
      "        [ 1.6954e-03, -9.3909e-04],\n",
      "        [-2.0303e-04,  7.7643e-05],\n",
      "        [-4.3899e-06, -1.0503e-05],\n",
      "        [-1.0106e-09,  4.0530e-07],\n",
      "        [ 5.0736e-05, -1.4764e-05],\n",
      "        [ 5.5014e-05, -2.9367e-05],\n",
      "        [ 2.6504e-05, -2.6217e-05],\n",
      "        [ 3.5299e-05, -1.6995e-05],\n",
      "        [ 3.3096e-06, -3.2115e-06],\n",
      "        [ 2.5623e-05, -4.0940e-05],\n",
      "        [-2.3711e-05, -2.6847e-05],\n",
      "        [ 4.1972e-05, -1.1248e-05],\n",
      "        [ 2.2882e-05,  1.2255e-06],\n",
      "        [ 1.4371e-05, -3.6050e-05],\n",
      "        [-7.0160e-06,  2.8960e-05],\n",
      "        [ 2.2769e-05,  3.3133e-05],\n",
      "        [ 3.9527e-05,  2.6858e-05],\n",
      "        [ 2.3989e-05, -2.5211e-06],\n",
      "        [ 5.7543e-06, -2.9620e-06],\n",
      "        [-2.0750e-05, -3.5393e-06],\n",
      "        [ 1.0889e-03, -8.1875e-04],\n",
      "        [ 1.6217e-05, -1.7386e-05],\n",
      "        [ 3.7058e-05, -6.8663e-08],\n",
      "        [ 1.4267e-03, -1.3930e-03],\n",
      "        [-4.2939e-05,  1.0980e-06],\n",
      "        [-1.5519e-04, -1.2182e-04],\n",
      "        [ 1.3245e-03, -5.7058e-04],\n",
      "        [ 3.9279e-04, -9.8731e-04],\n",
      "        [-5.2055e-06, -1.0430e-05],\n",
      "        [ 1.1768e-03, -3.4913e-05],\n",
      "        [ 2.2364e-05,  2.9858e-06],\n",
      "        [-6.6194e-06,  3.3266e-06],\n",
      "        [ 2.2748e-05, -1.7909e-05],\n",
      "        [-9.7807e-07,  1.7024e-05],\n",
      "        [ 2.8413e-05, -2.7883e-06],\n",
      "        [ 5.9046e-06, -4.5089e-05],\n",
      "        [ 1.3459e-06,  3.3442e-07],\n",
      "        [ 1.9299e-05, -2.0594e-05],\n",
      "        [ 2.7774e-03,  2.4377e-03],\n",
      "        [-3.6415e-05, -1.4327e-04],\n",
      "        [ 3.0064e-05, -6.7186e-05],\n",
      "        [ 1.5139e-03,  3.1173e-04],\n",
      "        [ 3.4204e-06,  1.9550e-06],\n",
      "        [-1.0757e-04,  4.1468e-06],\n",
      "        [ 3.9825e-04, -2.6800e-04],\n",
      "        [ 1.4856e-05, -5.6364e-06],\n",
      "        [ 1.6298e-06, -5.5271e-07],\n",
      "        [ 5.4046e-05, -3.6072e-05],\n",
      "        [ 9.4290e-04,  1.0230e-03],\n",
      "        [ 1.6187e-05,  1.1125e-05],\n",
      "        [ 4.3525e-06, -1.3550e-06],\n",
      "        [ 1.9942e-05, -3.3558e-05],\n",
      "        [ 3.9126e-05,  4.7026e-06],\n",
      "        [ 2.1039e-05, -1.9452e-04],\n",
      "        [ 6.9844e-06, -2.8334e-05],\n",
      "        [ 2.1352e-05, -3.7376e-05],\n",
      "        [ 2.3091e-05,  3.3642e-06],\n",
      "        [ 5.1659e-06,  1.0943e-05],\n",
      "        [ 1.8431e-03, -9.3773e-04],\n",
      "        [ 1.8964e-05,  1.2611e-05]], device='cuda:0', grad_fn=<MmBackward0>) tensor([[ 1.0743e-03, -1.7510e-03],\n",
      "        [ 5.4436e-04, -4.4834e-04],\n",
      "        [-4.1899e-07, -1.8757e-06],\n",
      "        [-1.2891e-05, -5.9752e-05],\n",
      "        [ 1.6954e-03, -9.3909e-04],\n",
      "        [-2.0303e-04,  7.7643e-05],\n",
      "        [-4.3899e-06, -1.0503e-05],\n",
      "        [-1.0106e-09,  4.0530e-07],\n",
      "        [ 5.0736e-05, -1.4764e-05],\n",
      "        [ 5.5014e-05, -2.9367e-05],\n",
      "        [ 2.6504e-05, -2.6217e-05],\n",
      "        [ 3.5299e-05, -1.6995e-05],\n",
      "        [ 3.3096e-06, -3.2115e-06],\n",
      "        [ 2.5623e-05, -4.0940e-05],\n",
      "        [-2.3711e-05, -2.6847e-05],\n",
      "        [ 4.1972e-05, -1.1248e-05],\n",
      "        [ 2.2882e-05,  1.2255e-06],\n",
      "        [ 1.4371e-05, -3.6050e-05],\n",
      "        [-7.0160e-06,  2.8960e-05],\n",
      "        [ 2.2769e-05,  3.3133e-05],\n",
      "        [ 3.9527e-05,  2.6858e-05],\n",
      "        [ 2.3989e-05, -2.5211e-06],\n",
      "        [ 5.7543e-06, -2.9620e-06],\n",
      "        [-2.0750e-05, -3.5393e-06],\n",
      "        [ 1.0889e-03, -8.1875e-04],\n",
      "        [ 1.6217e-05, -1.7386e-05],\n",
      "        [ 3.7058e-05, -6.8663e-08],\n",
      "        [ 1.4267e-03, -1.3930e-03],\n",
      "        [-4.2939e-05,  1.0980e-06],\n",
      "        [-1.5519e-04, -1.2182e-04],\n",
      "        [ 1.3245e-03, -5.7058e-04],\n",
      "        [ 3.9279e-04, -9.8731e-04],\n",
      "        [-5.2055e-06, -1.0430e-05],\n",
      "        [ 1.1768e-03, -3.4913e-05],\n",
      "        [ 2.2364e-05,  2.9858e-06],\n",
      "        [-6.6194e-06,  3.3266e-06],\n",
      "        [ 2.2748e-05, -1.7909e-05],\n",
      "        [-9.7807e-07,  1.7024e-05],\n",
      "        [ 2.8413e-05, -2.7883e-06],\n",
      "        [ 5.9046e-06, -4.5089e-05],\n",
      "        [ 1.3459e-06,  3.3442e-07],\n",
      "        [ 1.9299e-05, -2.0594e-05],\n",
      "        [ 2.7774e-03,  2.4377e-03],\n",
      "        [-3.6415e-05, -1.4327e-04],\n",
      "        [ 3.0064e-05, -6.7186e-05],\n",
      "        [ 1.5139e-03,  3.1173e-04],\n",
      "        [ 3.4204e-06,  1.9550e-06],\n",
      "        [-1.0757e-04,  4.1468e-06],\n",
      "        [ 3.9825e-04, -2.6800e-04],\n",
      "        [ 1.4856e-05, -5.6364e-06],\n",
      "        [ 1.6298e-06, -5.5271e-07],\n",
      "        [ 5.4046e-05, -3.6072e-05],\n",
      "        [ 9.4290e-04,  1.0230e-03],\n",
      "        [ 1.6187e-05,  1.1125e-05],\n",
      "        [ 4.3525e-06, -1.3550e-06],\n",
      "        [ 1.9942e-05, -3.3558e-05],\n",
      "        [ 3.9126e-05,  4.7026e-06],\n",
      "        [ 2.1039e-05, -1.9452e-04],\n",
      "        [ 6.9844e-06, -2.8334e-05],\n",
      "        [ 2.1352e-05, -3.7376e-05],\n",
      "        [ 2.3091e-05,  3.3642e-06],\n",
      "        [ 5.1659e-06,  1.0943e-05],\n",
      "        [ 1.8431e-03, -9.3773e-04],\n",
      "        [ 1.8964e-05,  1.2611e-05]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
      "        0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0], device='cuda:0') tensor([2, 2, 1, 0, 2, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        2, 1, 0, 2, 0, 1, 2, 2, 1, 2, 1, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 2, 0, 1,\n",
      "        2, 0, 1, 0, 2, 1, 1, 1, 1, 0, 0, 1, 1, 0, 2, 0], device='cuda:0') tensor([[135.,  95., 520.],\n",
      "        [120.,  55., 485.],\n",
      "        [125., 100., 500.],\n",
      "        [110.,  70., 485.],\n",
      "        [105.,  65., 495.],\n",
      "        [145., 100., 490.],\n",
      "        [125.,  60., 475.],\n",
      "        [120.,  55., 520.],\n",
      "        [100., 150., 500.],\n",
      "        [135., 130., 515.],\n",
      "        [135., 100., 505.],\n",
      "        [150.,  95., 475.],\n",
      "        [140.,  60., 490.],\n",
      "        [145., 145., 495.],\n",
      "        [110., 100., 515.],\n",
      "        [135., 135., 505.],\n",
      "        [105.,  55., 495.],\n",
      "        [115.,  65., 510.],\n",
      "        [150., 145., 515.],\n",
      "        [135., 100., 510.],\n",
      "        [150., 130., 495.],\n",
      "        [105.,  60., 515.],\n",
      "        [120.,  50., 500.],\n",
      "        [120., 120., 505.],\n",
      "        [145.,  70., 520.],\n",
      "        [145., 145., 490.],\n",
      "        [140., 150., 525.],\n",
      "        [125.,  75., 490.],\n",
      "        [125.,  75., 525.],\n",
      "        [135., 100., 480.],\n",
      "        [145.,  55., 515.],\n",
      "        [135.,  60., 495.],\n",
      "        [110., 120., 490.],\n",
      "        [110.,  70., 515.],\n",
      "        [115.,  70., 495.],\n",
      "        [120., 105., 490.],\n",
      "        [140., 125., 515.],\n",
      "        [130.,  60., 480.],\n",
      "        [110.,  65., 520.],\n",
      "        [140., 125., 480.],\n",
      "        [150.,  50., 485.],\n",
      "        [110., 130., 480.],\n",
      "        [135.,  75., 495.],\n",
      "        [135., 100., 505.],\n",
      "        [135., 140., 505.],\n",
      "        [120.,  75., 480.],\n",
      "        [135.,  50., 520.],\n",
      "        [125.,  80., 475.],\n",
      "        [130.,  85., 505.],\n",
      "        [150., 105., 510.],\n",
      "        [135.,  50., 510.],\n",
      "        [105.,  90., 510.],\n",
      "        [110.,  90., 510.],\n",
      "        [110., 140., 485.],\n",
      "        [145.,  65., 480.],\n",
      "        [150., 135., 485.],\n",
      "        [145., 130., 495.],\n",
      "        [100., 100., 485.],\n",
      "        [135., 105., 525.],\n",
      "        [135.,  70., 500.],\n",
      "        [120., 140., 505.],\n",
      "        [130., 150., 510.],\n",
      "        [110.,  90., 520.],\n",
      "        [145.,  80., 480.]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1720538456841/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1720538456841/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1720538456841/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1720538456841/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [24,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1720538456841/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [27,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1720538456841/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [30,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1720538456841/work/aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [31,0,0] Assertion `t >= 0 && t < n_classes` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# performe training and validation loops\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m train_inverse(train_dataloader, model, loss_reg, loss_ce, optimizer, device)\n\u001b[1;32m     21\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m val_inverse(val_dataloader, model, loss_reg, loss_ce, device)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# log training and validation loss to console\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/didattica/Eosam2024/notebooks/../loops.py:60\u001b[0m, in \u001b[0;36mtrain_inverse\u001b[0;34m(dataloader, model, loss_reg, loss_ce, optimizer, device)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred_l,pred_m,pred_g)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(true_l,true_m,true_g)\n\u001b[0;32m---> 60\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_ce(pred_l, true_l) \u001b[38;5;241m+\u001b[39m loss_ce(pred_m, true_m) \u001b[38;5;241m+\u001b[39m loss_reg(pred_g, true_g) \n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[1;32m     63\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# create timestamp\n",
    "now = datetime.now()  # current date and time\n",
    "date_time = now.strftime(\"%d%m%y_%H%M%S\")\n",
    "\n",
    "# create summary writer for tensorboard\n",
    "writer_path = '../tb_logs/inverse_' + date_time + '/'\n",
    "writer = SummaryWriter(writer_path)\n",
    "\n",
    "# loop over epochs\n",
    "epochs = 5000\n",
    "epoch_threshold = 500\n",
    "save_checkpoint = './best_inverse_model_' + date_time + '.ckpt'\n",
    "best_loss = 1.0\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # log epoch to console\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "\n",
    "    # performe training and validation loops\n",
    "    train_loss = train_inverse(train_dataloader, model, loss_reg, loss_ce, optimizer, device)\n",
    "    val_loss = val_inverse(val_dataloader, model, loss_reg, loss_ce, device)\n",
    "\n",
    "    # log training and validation loss to console\n",
    "    writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "    writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "\n",
    "    # save checkpoint\n",
    "    if (val_loss < best_loss) and (epoch>epoch_threshold):\n",
    "        \n",
    "        # save checkpoint\n",
    "        model.train()\n",
    "        torch.save(model.state_dict(), save_checkpoint)\n",
    "        best_loss = val_loss\n",
    "\n",
    "# close connection to tensorboard\n",
    "writer.flush()\n",
    "writer.close()\n",
    "\n",
    "# finished\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate inference model and set to evaluation mode\n",
    "model_inference = FlexibleMLP(hidden_layers=hidden_layers, activation=nn.GELU(), p=0.1).to(\n",
    "    device)\n",
    "model_inference.load_state_dict(torch.load(save_checkpoint,weights_only=True))\n",
    "model_inference.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute inference on all validation samples\n",
    "X_inference = torch.tensor(X_val.to_numpy().astype(np.float32)).to(device)\n",
    "y_inference = model_inference(X_inference)\n",
    "y_true = torch.tensor(np.stack(y_val.to_numpy()).astype(np.float32)).to(device)\n",
    "\n",
    "# compute normalized loss for each sample in the validation dataset\n",
    "loss_fn_inference = nn.MSELoss(reduction='none')\n",
    "with torch.no_grad():\n",
    "    loss_inference = loss_fn_inference(y_inference,y_true).sum(axis=-1)\n",
    "norm_mse_discrepancy = loss_inference/((y_true**2).sum(axis=-1))\n",
    "k_best = torch.argsort(norm_mse_discrepancy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = k_best[70]\n",
    "plt.plot(y_true[n_sample].cpu().detach())\n",
    "plt.plot(y_inference[n_sample].cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
