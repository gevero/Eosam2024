{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "\n",
    "# setup tensorboard for logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# local imports\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from datasets import SpectraDataset\n",
    "from models import MLP, ResidualMLP\n",
    "from loops import train,val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../DL-Assisted-NHA-Inverse-Design-/Dataset 6655.csv'\n",
    "test_val_split = 0.1  # portion of data assigned to validation set\n",
    "batch_size = 64  # batch size\n",
    "lr = 1.1e-4  # learning rate\n",
    "hidden_layers = [5, 2000, 2000, 2000, 2000, 2000, 200]  # structure of the neural network\n",
    "epochs = 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data into dataframe and clean them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename)\n",
    "df['Spectra'] = df.values[:,5:][:,::-1].tolist()\n",
    "df['Spectra'] = df['Spectra'].apply(np.array)\n",
    "df.drop(df.columns[5:-1], axis=1, inplace=True)\n",
    "df.columns = ['Lattice','Material','Thickness','Radius','Pitch','Spectra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split dataframe in train/val and features/labels (X/y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = df[['Lattice','Material','Thickness','Radius','Pitch']]\n",
    "X_df = X_df/X_df.max()\n",
    "y_df = df['Spectra']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_df, y_df, test_size=test_val_split, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = SpectraDataset(X_train,y_train)\n",
    "val_data = SpectraDataset(X_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle= True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing training device: cpu, gpu, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MLP(hidden_layers=hidden_layers).to(device)\n",
    "model = ResidualMLP(hidden_layers=hidden_layers).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create summary writer for tensorboard\n",
    "now = datetime.now()  # current date and time\n",
    "date_time = now.strftime(\"%d%m%y_%H%M%S\")\n",
    "writer_path = '../tb_logs/' + date_time + '/'\n",
    "writer = SummaryWriter(writer_path)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train_loss = train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "    val_loss = val(val_dataloader, model, loss_fn, device)\n",
    "    writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "    writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "writer.flush()\n",
    "writer.close()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_val = iter(val_dataloader)\n",
    "val_sample = next(iter_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 59\n",
    "val_feature = val_sample[0][n_sample:n_sample+1]\n",
    "val_label = val_sample[1][n_sample:n_sample+1]\n",
    "nn_label = model(val_feature.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_label.T)\n",
    "plt.plot(nn_label.cpu().detach().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum((val_label-nn_label.cpu())**2)/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
